{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiesen243/neural-network/blob/main/multilayer-perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7no3AYuqv6qu"
      },
      "source": [
        "<h1 align='center'>Multiplayer Perceptron</hh1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 633,
      "metadata": {
        "id": "yDaM_KMqv6qz"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtIAU-LYv6q1"
      },
      "source": [
        "### Description\n",
        "- This model have 3 layers, 1 input layer, 1 hidden layer and 1 output layer.\n",
        "- The input layer have 2 neurons, the hidden layer have 3 neurons and the output layer have 2 neurons.\n",
        "- The activation function used in the hidden layer is the sigmoid function and in the output layer is the linear function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EskYwIjZv6q3"
      },
      "source": [
        "### Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 634,
      "metadata": {
        "id": "X5xCCESdv6q6"
      },
      "outputs": [],
      "source": [
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def linear(x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {
        "id": "X7n-epuBv6q7"
      },
      "outputs": [],
      "source": [
        "# Derivative of the activation function\n",
        "def d_sigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "def d_linear(x):\n",
        "    return 1\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Zikann5oac"
      },
      "source": [
        "## Hehe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {
        "id": "Bq5mDVkg6bxO"
      },
      "outputs": [],
      "source": [
        "class MLB:\n",
        "    def __init__(self, learning_rate=0.5, epochs=3):\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.V = None\n",
        "        self.W = None\n",
        "        self.A_h = sigmoid\n",
        "        self.dA_h = d_sigmoid\n",
        "        self.A_o = linear\n",
        "        self.dA_o = d_linear\n",
        "\n",
        "    def fit(self, X, D):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize weights\n",
        "        # Hidden layer with 3 neurons\n",
        "        self.V = np.random.randn(n_features, 3)\n",
        "        # Output layer with 1 neuron\n",
        "        self.W = np.random.randn(3, 1)\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            for i, x_i in enumerate(X):\n",
        "                # Propagation\n",
        "\n",
        "                net_h = np.dot(self.V.T, x_i)\n",
        "                z = self.A_h(net_h)\n",
        "\n",
        "                net_o = np.dot(self.W.T, z)\n",
        "                y = self.A_o(net_o)\n",
        "\n",
        "                # Backpropagation\n",
        "\n",
        "                # Output layer\n",
        "                dE_dy = np.multiply((y - D[i]), self.dA_o(net_o))\n",
        "                dE_dnet_o = self.lr * dE_dy * z.reshape(-1, 1)\n",
        "\n",
        "                # Hidden layer\n",
        "                dE_dz = np.multiply(np.dot(self.W, dE_dy), self.dA_h(net_h))\n",
        "                dE_dnet_h = self.lr * np.dot(dE_dz.reshape(-1, 1), x_i.reshape(1, -1))\n",
        "\n",
        "                # Update weights\n",
        "                self.W -= dE_dnet_o\n",
        "                self.V -= dE_dnet_h.T\n",
        "\n",
        "    def predict(self, X):\n",
        "        net_h = np.dot(X, self.V)\n",
        "        z = self.A_h(net_h)\n",
        "\n",
        "        net_o = np.dot(z, self.W)\n",
        "        y = self.A_o(net_o)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 637,
      "metadata": {
        "id": "RxqAUI7z5swn"
      },
      "outputs": [],
      "source": [
        "data_train = pd.DataFrame(\n",
        "    {\"X1\": [0, 1, 2, -1], \"X2\": [1, -1, 0, 2], \"D\": [2, 5, 4, 13]}\n",
        ")\n",
        "\n",
        "data_test = pd.DataFrame({\"X1\": [5], \"X2\": [3], \"D\": [13]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 638,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = data_train[[\"X1\", \"X2\"]].values\n",
        "D_train = data_train[\"D\"].values\n",
        "\n",
        "mlb = MLB(epochs=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 639,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlb.fit(X_train, D_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 640,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.],\n",
              "       [ 5.],\n",
              "       [ 4.],\n",
              "       [13.]])"
            ]
          },
          "execution_count": 640,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlb.predict(data_train[[\"X1\", \"X2\"]].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 641,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.46914804e-06]])"
            ]
          },
          "execution_count": 641,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlb.predict(data_test[[\"X1\", \"X2\"]].values)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
